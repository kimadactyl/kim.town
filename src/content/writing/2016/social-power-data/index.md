---
title: 'Data is meaningless without social power'
description: "We have the data, but who is listening? How can we hope to solve social problems using open data when we're having trouble getting any kind of progress on social issues that have been widely documented for decades?"
pubDate: 'Nov 25 2016'
heroImage: './images/hero.jpg'
tags: ['critique', 'policing', 'data', 'activism']
source: 'gfsc'
externalUrl: 'https://gfsc.studio/blog/2016/social-power-data/'
---

I went to a film screening and discussion last week about Mark Duggan's shooting by the police, and the conditions surrounding him and his family.

The event was one of the best I've been to. The documentary itself was authentic, engaging, and honest, showing a slice of life in London in a similar fashion to an episode of _The Wire_. The discussion after was a real eye-opener for me: many speakers across two panels with so much to share and say.

Police use of body-worn cameras (BWCs) came up in the discussion at the end. A recent study showed that "the presence of BWCs reduces complaints against officers by 93%". The reasons for the reduction are still under debate, but the authors propose an idea of "contagious accountability".

However, the anecdotal but widely corroborated feeling at the event was that the police are still stop and searching young black people illegally, even wearing the BWCs: the children and young adults simply don't know what the procedure is so they don't ask for it. The BWC footage isn't reviewed because, paraphrasing one speaker, "if noone gets shot, noone looks at the footage". And noone, especially noone who the police harass already, is going to make a fuss over missing documentation.

Then it hit me: we have the data, but choose to ignore it. Much as racism is meaningless without social power, so too is data.

We have an enormous amount of data spanning decades on the institutional racism in the UK. 1578 deaths in police custody or following contact with the police since 1990, with 0 convictions. We know that Muslim candidates are 2.5 times less likely to get a job than their Caucasian counterparts with identical CVs. We know that black people are 17 times more likely to be stop and searched than white in some areas. So where is our "big data" and "data science" for racism?

## Echo Chambers

When we think of an echo chamber we tend to think of the social media bubble, but we think less about the echo chambers of our communities of choice or employment. Social media has strongly shifted the emphasis on who we talk to: from communities of location or demographic, to communities of choice. I think to break out of these bubbles, we need to look locally, look at power and who has it, and look at habitus: all technology is a product of its social context, and the agendas of the people creating it.

Currently there's a huge amount of hype and money around the tech sector. At the screening, it was commented that the University of Manchester barely represents the communities in Moss Side and Salford around it; so too our startups and tech events poorly reflect those they try and represent. I wonder if this lack of interaction is inadvertently simply reproducing the same power imbalance in the world as a whole, and that by not being embedded in community organisations, not working with community groups to understand and create solutions together, we are in no position to challenge the "echo chambers" that are currently emerging.

## Stop Making Apps

Tin Geber, a technologist involved in refugee action, asks people simply to "_stop making apps_". Apps, to Geber, do nothing to solve the important problems facing refugees. He urges readers to get involved first, and listen a while, before trying to plough on with a solution. By contrast the app is the almost default strategy of the technology initiative or hack day. There are dozens of hack days in Manchester. As far as I can tell, none of these have focussed on topics as difficult or complex as racism, sexism, migration or homophobia, in favour of easier topics like connecting your toaster to the internet. This is not to bash on hobbyists, but an acknowledgement that _as_ technologists, we should be engaging in social issues first, and building software second.

We need to be drawn not to the extreme, exciting, new, or sexy _technology_, but to the needs of our community: which should be just as exciting in a different way. We need to spend a lot more time listening and engaging and being part of solutions. Borrowing Paulo Freire's critique of education: social good is not a bucket you fill, in order to deliver it to someone who needs it. Social good is working together to challenge the conditions that create inequality in the first place.

As socially engaged citizens who work with data, we cannot ignore the power structures that create, manipulate, publish, and use, data. Just as data is only given context by interpretation, so too we need to analyse the power structures that surround it. Only by working with communities to use data to its fullest extent can we hope to challenge the inequality in the world today. Let's let technology ride the back seat for a while and get back to getting to know the people around us.
